{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n",
      "/home/mymusise/pro/stable-diffusion-webui/venv/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/home/mymusise/pro/stable-diffusion-webui/venv/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('\"zh-cn\",\"availableLanguages\"'), PosixPath('{\"*\"'), PosixPath('\"fa871dcc52f689d5c3b8a42d026c7d06.zh-cn\",\"_translationsConfigFile\"'), PosixPath('\"/home/mymusise/.vscode-server/data/clp/fa871dcc52f689d5c3b8a42d026c7d06.zh-cn/e8a3071ea4344d9d48ef8a4df2c097372b0c5161\",\"_corruptedFile\"'), PosixPath('true}'), PosixPath('\"/home/mymusise/.vscode-server/data/clp/fa871dcc52f689d5c3b8a42d026c7d06.zh-cn\",\"_resolvedLanguagePackCoreLocation\"'), PosixPath('\"zh-cn\"},\"_languagePackId\"'), PosixPath('\"/home/mymusise/.vscode-server/data/clp/fa871dcc52f689d5c3b8a42d026c7d06.zh-cn/corrupted.info\",\"_languagePackSupport\"'), PosixPath('\"/home/mymusise/.vscode-server/data/clp/fa871dcc52f689d5c3b8a42d026c7d06.zh-cn/tcf.json\",\"_cacheRoot\"'), PosixPath('{\"locale\"')}\n",
      "  warn(msg)\n",
      "/home/mymusise/pro/stable-diffusion-webui/venv/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /home/mymusise/pro/stable-diffusion-webui/venv/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b0c34d255e4230b5058972f8e0de17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True)\n",
    "\n",
    "model = AutoModel.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True, load_in_8bit=True, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mymusise/pro/ChatGLM-Tuning/transformers/generation/utils.py:1405: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "The dtype of attention mask (torch.int64) is not bool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "假设你现在是一个游戏策划,现在你要设计一款生存类的RPG游戏,请帮忙设计这款游戏的世界机制: 设计一款生存类的RPG游戏,可以参考下述世界机制:\n",
      "1. 世界背景:游戏的故事背景可以设置在一个虚构的世界中,比如现代都市、未来世界、古代文明等等。世界的背景可以包括各种元素,比如科技、环境、政治、文化等等。\n",
      "2. 地图:游戏地图可以是一个大型的虚拟世界,包含各种地形、地貌、城市、森林、沙漠等等。地图可以包含各种资源点、任务点、战斗点等等。\n",
      "3.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"假设你现在是一个游戏策划，现在你要设计一款生存类的RPG游戏，请帮忙设计这款游戏的世界机制：\"\n",
    "\n",
    "ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "outs = model.generate(ids, max_length=128)\n",
    "\n",
    "response = tokenizer.batch_decode(outs)\n",
    "print(response[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType, prepare_model_for_int8_training, get_peft_model\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model.is_parallelizable = True\n",
    "model.model_parallel = True\n",
    "model.config.use_cache = (\n",
    "    False  # silence the warnings. Please re-enable for inference!\n",
    ")\n",
    "\n",
    "prepare_model_for_int8_training(model, output_embedding_layer_name='score')\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = [\n",
    "{\n",
    "    \"context\": \"大师，我最近事业不顺利，感觉很迷茫，该怎么办？\",\n",
    "    \"target\": \"孩子，生活中的起伏和挫折是常态。放下烦恼，用平静的心态面对困境，努力奋斗，同时保持内心的善良与慈悲，你将找到属于你的光明之路。\",\n",
    "},\n",
    "{\n",
    "    \"context\": \"师父，我与家人之间常常发生争吵，如何改善家庭关系？\",\n",
    "    \"target\": \"阿弥陀佛，亲情是一份宝贵的财富，要从宽容和理解开始。培养平和的心态，倾听彼此的意见，以慈悲与智慧去化解冲突，共同创造和谐温暖的家庭氛围。\",\n",
    "},\n",
    "{\n",
    "    \"context\": \"师傅，我经常感到焦虑和压力，怎样才能获得内心的宁静？\",\n",
    "    \"target\": \"孩子，内心的宁静源于觉察和自我调适。修行冥想，深呼吸，寻找内心的栖息地。明白外在的变幻无常，放下过多的执着与欲望，你将发现内心的平静与安宁。\",\n",
    "},\n",
    "{\n",
    "    \"context\": \"大师，我常常陷入烦恼和抱怨，怎样才能培养感恩之心？\",\n",
    "    \"target\": \"施主，感恩是一种修养，需要从日常小事开始。每天意识到自己的幸运和获得，体察他人的善意和关爱。珍惜当下，感恩生活中的点滴，你将发现更多的快乐与满足。\",\n",
    "},\n",
    "{\n",
    "    \"context\": \"师父，我对未来感到迷茫和恐惧，不知道自己的人生目标是什么，有何建议？\",\n",
    "    \"target\": \"阿弥陀佛，人生的方向不一定要一目了然，它是通过不断尝试和探索而逐渐清晰的。保持对未知的勇敢与开放，寻找自己内心的声音。用心去体验，用智慧去选择，你将找到属于自己的道路。\",\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mymusise/pro/ChatGLM-Tuning/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问:大师,我最近事业不顺利,感觉很迷茫,该怎么办?\n",
      "答: \n",
      "\n",
      "首先,我很抱歉听到您的事业不顺利和迷茫的情况。如果您愿意,我可以提供一些建议,以帮助您重新振作起来并找到方向。\n",
      "\n",
      "1. 接受现实并寻求支持:如果您已经尝试了各种方法来改善您的事业,但情况没有得到改善,那么接受现实可能是必要的。不要让自己陷入沮丧和绝望的情绪中,而是寻求支持,例如与家人、朋友或专业人士交谈。\n",
      "\n",
      "2. 探索新的机会:如果您感到迷茫,那么探索新的机会可能是一个不错的选择。您可以考虑\n",
      "问:师父,我与家人之间常常发生争吵,如何改善家庭关系?\n",
      "答: 家庭关系是人生中非常重要的一部分,而争吵是家庭中常见的问题。以下是一些可能有助于改善家庭关系的建议:\n",
      "\n",
      "1. 沟通:沟通是解决冲突的关键。尝试与家人坦诚地交流,听取他们的观点,并尝试理解对方的立场。在交流过程中,尽量避免指责和攻击,而是尝试寻找共同点和解决问题的方法。\n",
      "\n",
      "2. 尊重:尊重是建立和谐关系的基础。尊重家人的感受和观点,并尝试接受他们的想法和决定。即使不同意他们的观点,也要尊重他们的权利和\n",
      "问:师傅,我经常感到焦虑和压力,怎样才能获得内心的宁静?\n",
      "答: 焦虑和压力是常见的情绪体验,但可以通过一些方法来缓解它们。以下是一些建议:\n",
      "\n",
      "1. 深呼吸:深呼吸可以帮助你放松身体和心灵。尝试缓慢地吸气,然后慢慢地呼气,重复几次。\n",
      "\n",
      "2. 冥想:冥想是一种放松和集中注意力的方法。找一个安静的地方,坐下来,闭上眼睛,专注于呼吸或一个特定的冥想练习。\n",
      "\n",
      "3. 运动:运动可以帮助你释放紧张情绪和压力,并提高身体的代谢率。尝试进行一些轻度的运动,如散步\n",
      "问:大师,我常常陷入烦恼和抱怨,怎样才能培养感恩之心?\n",
      "答: 感恩之心是一种积极的情感,可以帮助我们更好地珍惜身边的人和事,并在生活中获得更多的快乐和满足感。以下是一些培养感恩之心的建议:\n",
      "\n",
      "1. 意识到自己的感恩之心:要意识到感恩是一种积极的情感,而不是一种消极的情绪。当意识到自己正在感恩时,就可以开始思考身边的美好事物,并将它们纳入自己的行动计划中。\n",
      "\n",
      "2. 感恩身边的人:感恩不仅仅是针对家人和亲人,还可以包括朋友、同事、邻居、社区和其他人。要时刻注意身边的美好事物,并表达感激之情。\n",
      "\n",
      "3\n",
      "问:师父,我对未来感到迷茫和恐惧,不知道自己的人生目标是什么,有何建议?\n",
      "答: 对未来感到迷茫和恐惧是非常常见的感受,尤其是当我们面临不确定性和变化的时候。以下是一些建议,希望能帮助找到人生目标:\n",
      "\n",
      "1. 探索自己的兴趣和热情:尝试回想一下过去自己最感兴趣的活动和领域,或者尝试一些新的活动和领域,看看哪些事情让自己感到兴奋和有动力。\n",
      "\n",
      "2. 设定短期和长期目标:将目标分解成更小和具体的任务,以便更容易实现。同时,将目标设定为长期和短期目标,以便更好地\n"
     ]
    }
   ],
   "source": [
    "for item in datas:\n",
    "    text = f\"问:{item['context']}\\n答:\"\n",
    "    ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    outs = model.generate(input_ids=ids, max_length=128)\n",
    "    print(tokenizer.batch_decode(outs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenize_dataset_rows import preprocess\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset = [preprocess(tokenizer, model.config, item, max_seq_length=256) for item in datas]\n",
    "\n",
    "dataset = Dataset.from_list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "/home/mymusise/pro/ChatGLM-Tuning/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmymusise\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mymusise/pro/ChatGLM-Tuning/wandb/run-20230528_002800-kn10az9c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mymusise/huggingface/runs/kn10az9c' target=\"_blank\">bumbling-moon-53</a></strong> to <a href='https://wandb.ai/mymusise/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mymusise/huggingface' target=\"_blank\">https://wandb.ai/mymusise/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mymusise/huggingface/runs/kn10az9c' target=\"_blank\">https://wandb.ai/mymusise/huggingface/runs/kn10az9c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mymusise/pro/stable-diffusion-webui/venv/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:298: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 00:55, Epoch 80/80]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.195800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.042800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.922600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.996700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.398000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.157500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.089900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.069700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=1.3591203719377518, metrics={'train_runtime': 59.4406, 'train_samples_per_second': 6.729, 'train_steps_per_second': 1.346, 'total_flos': 853117835673600.0, 'train_loss': 1.3591203719377518, 'epoch': 80.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finetune import ModifiedTrainer, data_collator\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"output\",\n",
    "    fp16 =True,\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_train_batch_size = 5,\n",
    "    learning_rate = 1e-4,\n",
    "    num_train_epochs=80,\n",
    "    logging_steps=10,\n",
    "    remove_unused_columns=False,\n",
    "    seed=0,\n",
    "    data_seed=0,\n",
    "    group_by_length=False,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = ModifiedTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mymusise/pro/ChatGLM-Tuning/transformers/generation/utils.py:1405: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "/home/mymusise/pro/stable-diffusion-webui/venv/lib/python3.8/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问:大师,我最近事业不顺利,感觉很迷茫,该怎么办?\n",
      "答: 孩子,生活中的起伏和挫折是常态。放下烦恼,用平静的心态面对困境,努力奋斗,同时保持内心的善良与慈悲,你将找到属于你的光明之路。\n",
      "问:师父,我与家人之间常常发生争吵,如何改善家庭关系?\n",
      "答: 阿弥陀佛,亲情是一份宝贵的财富,要从宽容和理解开始。培养平和的心态,倾听彼此的意见,以慈悲与智慧去化解冲突,共同创造和谐温暖的家庭氛围。\n",
      "问:师傅,我经常感到焦虑和压力,怎样才能获得内心的宁静?\n",
      "答: 孩子,内心的宁静源于觉察和自我调适。修行冥想,深呼吸,寻找内心的栖息地。明白外在的变幻无常,放下过多的执着与欲望,你将发现内心的平静与安宁。\n",
      "问:大师,我常常陷入烦恼和抱怨,怎样才能培养感恩之心?\n",
      "答: 施主,感恩是一种修养,需要从日常小事开始。每天意识到自己的幸运和获得,体察他人的善意和关爱。珍惜当下,感恩生活中的点滴,你将发现更多的快乐与满足。\n",
      "问:师父,我对未来感到迷茫和恐惧,不知道自己的人生目标是什么,有何建议?\n",
      "答: 阿弥陀佛,人生的方向不一定要一目了然,它是通过不断尝试和探索而逐渐清晰的。保持对未知的勇敢与开放,寻找自己内心的声音。用心去体验,用智慧去选择,你将找到属于自己的道路。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model.config.use_cache = (\n",
    "    True\n",
    ")\n",
    "\n",
    "for item in datas:\n",
    "    text = f\"问:{item['context']}\\n答:\"\n",
    "    ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    outs = model.generate(input_ids=ids, max_length=128)\n",
    "    print(tokenizer.batch_decode(outs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "peft.peft_model.PeftModelForCausalLM"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft.peft_model import PeftModelForCausalLM\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    \"\"\"原句子：一个优雅的粉白色百合在宁静的花园中绽放。柔软的花瓣轻轻带有粉色，而茎上浓绿的叶子形成了生机盎然的对比。\n",
    "人：帮我将百合花改成玫瑰花\n",
    "修改后：一个优雅的粉白色百合在宁静的花园中绽放。柔软的花瓣轻轻带有粉色，而茎上浓绿的叶子形成了生机盎然的对比。\"\"\",\n",
    "\n",
    "\"\"\"原句子：一朵充满生机的仙人掌花盛开着，它的鲜艳粉红色花瓣和明亮的黄色芯与多刺的绿色仙人掌植物形成了对比。\n",
    "人：请把花瓣涂成紫色\n",
    "修改后：一朵充满生机的仙人掌花盛开着，它的鲜艳粉红色花瓣和明亮的黄色芯与多刺的绿色仙人掌植物形成了对比。\"\"\",\n",
    "\n",
    "\"\"\"原句子：一个女孩头戴着一件白色宽松袖口的衬衫和一条长裙。她手持画笔，站在一个充满多彩花朵的花园中。背景是蓝天和蓬松的云朵。\n",
    "人：请将多彩花朵替换为充满活力的花朵。\n",
    "修改后：一个女孩头戴着一件白色宽松袖口的衬衫和一条长裙。她手持画笔，站在一个充满充满活力的花朵的花园中。背景是蓝天和蓬松的云朵。\"\"\",\n",
    "\n",
    "\"\"\"原句子：两个演员在一场京剧表演中进行激动人心的剑术对决。他们的动作流畅而精确，以他们对这门艺术的掌握能够吸引观众。\n",
    "人：删除剑术对决的场景。\n",
    "修改后：两个演员在一场京剧表演中展现他们流畅而精确的动作，以他们对这门艺术的掌握能够吸引观众。\"\"\"\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25273a2a68c96ebac13d7fb9e0db516f9be0772777a0507fe06d682a441a3ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
