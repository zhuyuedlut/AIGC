{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True, load_in_8bit=True, device_map='auto')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_text = \"假设你现在是一个游戏策划，现在你要设计一款生存类的RPG游戏，请帮忙设计这款游戏的世界机制：\"\n",
    "\n",
    "ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "outs = model.generate(ids, max_length=128)\n",
    "response = tokenizer.batch_decode(outs)\n",
    "print(response[0])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType, prepare_model_for_int8_training, get_peft_model\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model.is_parallelizable = True\n",
    "model.model_parallel = True\n",
    "model.config.use_cache = (\n",
    "    False  # silence the warnings. Please re-enable for inference!\n",
    ")\n",
    "\n",
    "prepare_model_for_int8_training(model)\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datas = [\n",
    "{\n",
    "    \"context\": \"大师，我最近事业不顺利，感觉很迷茫，该怎么办？\",\n",
    "    \"target\": \"孩子，生活中的起伏和挫折是常态。放下烦恼，用平静的心态面对困境，努力奋斗，同时保持内心的善良与慈悲，你将找到属于你的光明之路。\",\n",
    "},\n",
    "{\n",
    "    \"context\": \"师父，我与家人之间常常发生争吵，如何改善家庭关系？\",\n",
    "    \"target\": \"阿弥陀佛，亲情是一份宝贵的财富，要从宽容和理解开始。培养平和的心态，倾听彼此的意见，以慈悲与智慧去化解冲突，共同创造和谐温暖的家庭氛围。\",\n",
    "},\n",
    "{\n",
    "    \"context\": \"师傅，我经常感到焦虑和压力，怎样才能获得内心的宁静？\",\n",
    "    \"target\": \"孩子，内心的宁静源于觉察和自我调适。修行冥想，深呼吸，寻找内心的栖息地。明白外在的变幻无常，放下过多的执着与欲望，你将发现内心的平静与安宁。\",\n",
    "},\n",
    "{\n",
    "    \"context\": \"大师，我常常陷入烦恼和抱怨，怎样才能培养感恩之心？\",\n",
    "    \"target\": \"施主，感恩是一种修养，需要从日常小事开始。每天意识到自己的幸运和获得，体察他人的善意和关爱。珍惜当下，感恩生活中的点滴，你将发现更多的快乐与满足。\",\n",
    "},\n",
    "{\n",
    "    \"context\": \"师父，我对未来感到迷茫和恐惧，不知道自己的人生目标是什么，有何建议？\",\n",
    "    \"target\": \"阿弥陀佛，人生的方向不一定要一目了然，它是通过不断尝试和探索而逐渐清晰的。保持对未知的勇敢与开放，寻找自己内心的声音。用心去体验，用智慧去选择，你将找到属于自己的道路。\",\n",
    "}]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for item in datas:\n",
    "    text = f\"问:{item['context']}\\n答:\"\n",
    "    ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    outs = model.generate(input_ids=ids, max_length=128)\n",
    "    print(tokenizer.batch_decode(outs)[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tokenizer_dataset_rows import preprocess\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset = [preprocess(tokenizer, model.config, item, max_seq_length=256) for item in datas]\n",
    "dataset = Dataset.from_list(dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from finetune import ModifiedTrainer, data_collator\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"output\",\n",
    "    fp16 =True,\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_train_batch_size = 5,\n",
    "    learning_rate = 1e-4,\n",
    "    num_train_epochs=80,\n",
    "    logging_steps=10,\n",
    "    remove_unused_columns=False,\n",
    "    seed=0,\n",
    "    data_seed=0,\n",
    "    group_by_length=False,\n",
    ")\n",
    "\n",
    "trainer = ModifiedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.config.use_cache = (\n",
    "    True\n",
    ")\n",
    "\n",
    "for item in datas:\n",
    "    text = f\"问:{item['context']}\\n答:\"\n",
    "    ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    outs = model.generate(input_ids=ids, max_length=128)\n",
    "    print(tokenizer.batch_decode(outs)[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
