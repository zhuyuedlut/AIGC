{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-02T07:44:30.793378Z",
     "start_time": "2023-06-02T07:25:36.871543Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading (…)model.bin.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1afc925bfe0a4a7397a4da0cf68ca34c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0f438d4c96f4ddaa25a12622db16a36"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)l-00001-of-00008.bin:   0%|          | 0.00/1.74G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "069a677a8a1541bcb001fa2d36b6e2fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)l-00002-of-00008.bin:   0%|          | 0.00/1.88G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c37472289e2b4fe4b5167d5d17af8d76"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)l-00003-of-00008.bin:   0%|          | 0.00/1.98G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c68a15544c4c451781e0807acec09086"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)l-00004-of-00008.bin:   0%|          | 0.00/1.91G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c786967c37f94c02acd49c04bfc6022d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)l-00005-of-00008.bin:   0%|          | 0.00/1.88G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d27e906f0894c999e0b324187efdfa0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)l-00006-of-00008.bin:   0%|          | 0.00/1.88G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0dd89c9234344568b25767e4fb7aa50e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)l-00007-of-00008.bin:   0%|          | 0.00/1.07G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2efa21f1b115491da8dc64ba883fe2d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)l-00008-of-00008.bin:   0%|          | 0.00/1.07G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e723d875d7b44d03b2e1fa3e13405e71"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/server/anaconda3/envs/llm/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /home/server/anaconda3/envs/llm/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/server/anaconda3/envs/llm/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/home/server/anaconda3/envs/llm/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5fb94bc9be8c4b99ac63aa42682e24cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True, load_in_8bit=True, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "假设你现在是一个游戏策划,现在你要设计一款生存类的RPG游戏,请帮忙设计这款游戏的世界机制: 设计一款生存类的RPG游戏,可以参考下述世界机制:\n",
      "1. 世界背景:游戏的故事背景可以设置在一个虚构的世界中,比如现代都市、未来世界、古代文明等等。世界的背景可以包括各种元素,比如科技、环境、政治、文化等等。\n",
      "2. 地图:游戏地图可以是一个大型的虚拟世界,包含各种地形、地貌、城市、森林、沙漠等等。地图可以包含各种资源点、任务点、战斗点等等。\n",
      "3.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"假设你现在是一个游戏策划，现在你要设计一款生存类的RPG游戏，请帮忙设计这款游戏的世界机制：\"\n",
    "\n",
    "ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "outs = model.generate(ids, max_length=128)\n",
    "response = tokenizer.batch_decode(outs)\n",
    "print(response[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T07:45:33.798210Z",
     "start_time": "2023-06-02T07:45:18.985797Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType, prepare_model_for_int8_training, get_peft_model\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model.is_parallelizable = True\n",
    "model.model_parallel = True\n",
    "model.config.use_cache = (\n",
    "    False  # silence the warnings. Please re-enable for inference!\n",
    ")\n",
    "\n",
    "prepare_model_for_int8_training(model)\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T08:02:48.065581Z",
     "start_time": "2023-06-02T08:02:37.752106Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "datas = [\n",
    "{\n",
    "    \"context\": \"大师，我最近事业不顺利，感觉很迷茫，该怎么办？\",\n",
    "    \"target\": \"孩子，生活中的起伏和挫折是常态。放下烦恼，用平静的心态面对困境，努力奋斗，同时保持内心的善良与慈悲，你将找到属于你的光明之路。\",\n",
    "},\n",
    "{\n",
    "    \"context\": \"师父，我与家人之间常常发生争吵，如何改善家庭关系？\",\n",
    "    \"target\": \"阿弥陀佛，亲情是一份宝贵的财富，要从宽容和理解开始。培养平和的心态，倾听彼此的意见，以慈悲与智慧去化解冲突，共同创造和谐温暖的家庭氛围。\",\n",
    "},\n",
    "{\n",
    "    \"context\": \"师傅，我经常感到焦虑和压力，怎样才能获得内心的宁静？\",\n",
    "    \"target\": \"孩子，内心的宁静源于觉察和自我调适。修行冥想，深呼吸，寻找内心的栖息地。明白外在的变幻无常，放下过多的执着与欲望，你将发现内心的平静与安宁。\",\n",
    "},\n",
    "{\n",
    "    \"context\": \"大师，我常常陷入烦恼和抱怨，怎样才能培养感恩之心？\",\n",
    "    \"target\": \"施主，感恩是一种修养，需要从日常小事开始。每天意识到自己的幸运和获得，体察他人的善意和关爱。珍惜当下，感恩生活中的点滴，你将发现更多的快乐与满足。\",\n",
    "},\n",
    "{\n",
    "    \"context\": \"师父，我对未来感到迷茫和恐惧，不知道自己的人生目标是什么，有何建议？\",\n",
    "    \"target\": \"阿弥陀佛，人生的方向不一定要一目了然，它是通过不断尝试和探索而逐渐清晰的。保持对未知的勇敢与开放，寻找自己内心的声音。用心去体验，用智慧去选择，你将找到属于自己的道路。\",\n",
    "}]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T08:02:49.664676Z",
     "start_time": "2023-06-02T08:02:49.657346Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/server/anaconda3/envs/llm/lib/python3.10/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "/home/server/anaconda3/envs/llm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问:大师,我最近事业不顺利,感觉很迷茫,该怎么办?\n",
      "答: \n",
      "\n",
      "首先,我很抱歉听到您的事业不顺利和迷茫的情况。如果您愿意,我可以提供一些建议,以帮助您重新振作起来并找到方向。\n",
      "\n",
      "1. 接受现实并寻求支持:如果您已经尝试了各种方法来改善您的事业,但情况没有得到改善,那么接受现实可能是必要的。不要让自己陷入沮丧和绝望的情绪中,而是寻求支持和建议,例如与朋友、家人或专业人士交流。\n",
      "\n",
      "2. 重新审视您的目标和价值观:考虑您的目标是什么,以及您的价值观是什么。这些\n",
      "问:师父,我与家人之间常常发生争吵,如何改善家庭关系?\n",
      "答: 家庭关系是人生中非常重要的一部分,而争吵是家庭中常见的问题。以下是一些可能有助于改善家庭关系的建议:\n",
      "\n",
      "1. 沟通:沟通是解决冲突的关键。尝试与家人坦诚地交流,听取他们的观点,并尝试找到共同点。在交流过程中,尽量避免指责和攻击,而是尝试解决问题。\n",
      "\n",
      "2. 尊重:尊重是建立和谐关系的基础。尊重家人的感受和观点,并尝试理解他们的立场。即使不同意他们的观点,也要尊重他们的意见,避免争吵。\n",
      "\n",
      "3.\n",
      "问:师傅,我经常感到焦虑和压力,怎样才能获得内心的宁静?\n",
      "答: 焦虑和压力是常见的情绪体验,但可以通过一些方法来缓解和克服它们。以下是一些建议:\n",
      "\n",
      "1. 深呼吸:深呼吸可以帮助你放松身体和心灵。尝试缓慢地吸气,然后慢慢地呼气,重复几次。\n",
      "\n",
      "2. 冥想:冥想是一种放松和集中注意力的方法。找一个安静的地方,坐下来,闭上眼睛,专注于呼吸或一个特定的冥想练习。\n",
      "\n",
      "3. 运动:运动可以帮助你释放紧张和焦虑情绪。尝试进行一些轻度的运动,如散步、瑜伽或慢跑\n",
      "问:大师,我常常陷入烦恼和抱怨,怎样才能培养感恩之心?\n",
      "答: 感恩之心是一种积极的情感,可以帮助我们更好地珍惜身边的人和事,并在生活中获得更多的快乐和满足感。以下是一些培养感恩之心的建议:\n",
      "\n",
      "1. 意识到自己的感恩之心:要意识到感恩是一种情感,而不是一种行为。当我们意识到自己正在感恩时,我们就能够更好地关注身边的人和事,并更加珍惜它们。\n",
      "\n",
      "2. 感恩身边的人:感恩不仅仅是针对家人和亲人,还可以包括朋友、同事、邻居等身边的人。与他们建立良好的关系,并经常表达你的感激之情,可以让你更加快乐和满足。\n",
      "\n",
      "\n",
      "问:师父,我对未来感到迷茫和恐惧,不知道自己的人生目标是什么,有何建议?\n",
      "答: 对未来感到迷茫和恐惧是非常常见的感受,很多人都会经历这种情况。以下是一些建议,希望能帮助找到人生目标:\n",
      "\n",
      "1. 探索自己的兴趣和热情:尝试回想一下过去自己最喜欢做的事情,或者最近感到最兴奋的事情。这些可能是自己的兴趣和热情所在,也可能是未来想要追求的方向。\n",
      "\n",
      "2. 设定短期和长期目标:将目标分解成短期和长期目标,更容易实现和评估进展。短期目标可以是每天或每周的任务,长期目标可以是一年或更长时间的计划\n"
     ]
    }
   ],
   "source": [
    "for item in datas:\n",
    "    text = f\"问:{item['context']}\\n答:\"\n",
    "    ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    outs = model.generate(input_ids=ids, max_length=128)\n",
    "    print(tokenizer.batch_decode(outs)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T08:04:22.358624Z",
     "start_time": "2023-06-02T08:02:58.422969Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from tokenizer_dataset_rows import preprocess\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset = [preprocess(tokenizer, model.config, item, max_seq_length=256) for item in datas]\n",
    "dataset = Dataset.from_list(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T08:19:24.595761Z",
     "start_time": "2023-06-02T08:19:23.916846Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "/home/server/anaconda3/envs/llm/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mzhuyuedluter\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.15.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/server/zhuyue/code/AIGC/lecture-03/wandb/run-20230602_163020-vo1lk5x1</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/zhuyuedluter/huggingface/runs/vo1lk5x1' target=\"_blank\">fluent-cherry-1</a></strong> to <a href='https://wandb.ai/zhuyuedluter/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/zhuyuedluter/huggingface' target=\"_blank\">https://wandb.ai/zhuyuedluter/huggingface</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/zhuyuedluter/huggingface/runs/vo1lk5x1' target=\"_blank\">https://wandb.ai/zhuyuedluter/huggingface/runs/vo1lk5x1</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/server/anaconda3/envs/llm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 2/80 : < :, Epoch 1/80]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=80, training_loss=1.0895731959491968, metrics={'train_runtime': 79.4077, 'train_samples_per_second': 5.037, 'train_steps_per_second': 1.007, 'total_flos': 853117835673600.0, 'train_loss': 1.0895731959491968, 'epoch': 80.0})"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finetune import ModifiedTrainer, data_collator\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"output\",\n",
    "    fp16 =True,\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_train_batch_size = 5,\n",
    "    learning_rate = 1e-4,\n",
    "    num_train_epochs=80,\n",
    "    logging_steps=10,\n",
    "    remove_unused_columns=False,\n",
    "    seed=0,\n",
    "    data_seed=0,\n",
    "    group_by_length=False,\n",
    ")\n",
    "\n",
    "trainer = ModifiedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T08:31:37.453597Z",
     "start_time": "2023-06-02T08:30:16.958328Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/server/anaconda3/envs/llm/lib/python3.10/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "/home/server/anaconda3/envs/llm/lib/python3.10/site-packages/transformers/generation/utils.py:1405: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/server/anaconda3/envs/llm/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问:大师,我最近事业不顺利,感觉很迷茫,该怎么办?\n",
      "答: 孩子,生活中的起伏和挫折是常态。放下烦恼,用平静的心态面对困境,努力奋斗,同时保持内心的善良与慈悲,你将找到属于你的光明之路。\n",
      "问:师父,我与家人之间常常发生争吵,如何改善家庭关系?\n",
      "答: 阿弥陀佛,亲情是一份宝贵的财富,要从宽容和理解开始。培养平和的心态,倾听彼此的意见,以慈悲与智慧去化解冲突,共同创造和谐温暖的家庭氛围。\n",
      "问:师傅,我经常感到焦虑和压力,怎样才能获得内心的宁静?\n",
      "答: 孩子,内心的宁静源于觉察和自我调适。修行冥想,深呼吸,寻找内心的栖息地。明白外在的变幻无常,放下过多的执着与欲望,你将发现内心的平静与安宁。\n",
      "问:大师,我常常陷入烦恼和抱怨,怎样才能培养感恩之心?\n",
      "答: 施主,感恩是一种修养,需要从日常小事开始。每天意识到自己的幸运和获得,体察他人的善意和关爱。珍惜当下,感恩生活中的点滴,你将发现更多的快乐与满足。\n",
      "问:师父,我对未来感到迷茫和恐惧,不知道自己的人生目标是什么,有何建议?\n",
      "答: 阿弥陀佛,人生的方向不一定要一目了然,它是通过不断尝试和探索而逐渐清晰的。保持对未知的勇敢与开放,寻找自己内心的声音。用心去体验,用智慧去选择,你将找到属于自己的道路。\n"
     ]
    }
   ],
   "source": [
    "model.config.use_cache = (\n",
    "    True\n",
    ")\n",
    "\n",
    "for item in datas:\n",
    "    text = f\"问:{item['context']}\\n答:\"\n",
    "    ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    outs = model.generate(input_ids=ids, max_length=128)\n",
    "    print(tokenizer.batch_decode(outs)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T08:33:57.332183Z",
     "start_time": "2023-06-02T08:33:27.809358Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
